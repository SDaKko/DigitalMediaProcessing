# fixed_tracking_final.py
# –ü–û–õ–ù–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø –î–õ–Ø –ò–ù–î–ò–í–ò–î–£–ê–õ–¨–ù–û–ì–û –ó–ê–î–ê–ù–ò–Ø –ü–û –¢–†–ï–ö–ò–ù–ì–£

import cv2
import numpy as np
import os
import time
import json
from datetime import datetime
import matplotlib.pyplot as plt

print("=== COMPLETE TRACKING ANALYSIS SYSTEM ===")
print(f"OpenCV version: {cv2.__version__}")


class TrackingAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∫–∞—á–µ—Å—Ç–≤–∞ —Ç—Ä–µ–∫–∏–Ω–≥–∞"""

    def __init__(self):
        self.metrics = {
            'success_frames': 0,
            'total_frames': 0,
            'tracking_loss_count': 0,
            'recovery_count': 0,
            'center_positions': [],
            'bbox_sizes': [],
            'processing_times': []
        }

    def update(self, success, bbox, processing_time):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫"""
        self.metrics['total_frames'] += 1
        self.metrics['processing_times'].append(processing_time)

        if success:
            self.metrics['success_frames'] += 1
            x, y, w, h = bbox
            center = (x + w / 2, y + h / 2)
            self.metrics['center_positions'].append(center)
            self.metrics['bbox_sizes'].append((w, h))

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ –ø–æ—Ç–µ—Ä–∏
            if len(self.metrics['center_positions']) > 1 and self.metrics['tracking_loss_count'] > 0:
                prev_center = self.metrics['center_positions'][-2]
                distance = np.sqrt((center[0] - prev_center[0]) ** 2 + (center[1] - prev_center[1]) ** 2)
                if distance < 50:  # –ü–æ—Ä–æ–≥ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
                    self.metrics['recovery_count'] += 1
        else:
            self.metrics['tracking_loss_count'] += 1
            self.metrics['center_positions'].append(None)
            self.metrics['bbox_sizes'].append(None)

    def calculate_metrics(self):
        """–†–∞—Å—á–µ—Ç –∏—Ç–æ–≥–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫"""
        total_frames = self.metrics['total_frames']
        success_frames = self.metrics['success_frames']

        metrics = {
            'success_rate': (success_frames / total_frames * 100) if total_frames > 0 else 0,
            'tracking_loss_frequency': (
                        self.metrics['tracking_loss_count'] / total_frames * 100) if total_frames > 0 else 0,
            'recovery_rate': (self.metrics['recovery_count'] / self.metrics['tracking_loss_count'] * 100) if
            self.metrics['tracking_loss_count'] > 0 else 0,
            'average_processing_time': np.mean(self.metrics['processing_times']) if self.metrics[
                'processing_times'] else 0,
            'stability_score': self._calculate_stability(),
            'total_frames_processed': total_frames
        }
        return metrics

    def _calculate_stability(self):
        """–†–∞—Å—á–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ —Ç—Ä–µ–∫–∏–Ω–≥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞ bbox"""
        if len(self.metrics['bbox_sizes']) < 2:
            return 0

        sizes = [size for size in self.metrics['bbox_sizes'] if size is not None]
        if len(sizes) < 2:
            return 0

        size_changes = []
        for i in range(1, len(sizes)):
            area1 = sizes[i - 1][0] * sizes[i - 1][1]
            area2 = sizes[i][0] * sizes[i][1]
            change = abs(area2 - area1) / area1
            size_changes.append(change)

        stability = 1 - np.mean(size_changes)
        return max(0, min(1, stability)) * 100


class TrackingSystem:
    def __init__(self):
        self.tracker = None
        self.tracker_type = None
        self.trajectory = []
        self.is_initialized = False
        self.analyzer = TrackingAnalyzer()

    def initialize_tracker(self, tracker_type='CSRT'):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç—Ä–µ–∫–µ—Ä–∞"""
        try:
            if tracker_type == 'CSRT':
                self.tracker = cv2.legacy.TrackerCSRT_create()
            elif tracker_type == 'KCF':
                self.tracker = cv2.legacy.TrackerKCF_create()
            elif tracker_type == 'MOSSE':
                self.tracker = cv2.legacy.TrackerMOSSE_create()
            else:
                print(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø —Ç—Ä–µ–∫–µ—Ä–∞: {tracker_type}")
                return False

            self.tracker_type = tracker_type
            print(f"‚úÖ –¢—Ä–µ–∫–µ—Ä {tracker_type} —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç—Ä–µ–∫–µ—Ä–∞ {tracker_type}: {e}")
            return False

    def init_tracking(self, frame, bbox):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Å –≤—ã–±—Ä–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç—å—é"""
        if self.tracker is None:
            print("‚ùå –¢—Ä–µ–∫–µ—Ä –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return False

        try:
            success = self.tracker.init(frame, bbox)
            if success:
                self.is_initialized = True
                self.trajectory = []
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—É—é —Ç–æ—á–∫—É –≤ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—é
                x, y, w, h = bbox
                center = (int(x + w / 2), int(y + h / 2))
                self.trajectory.append(center)
                print(f"‚úÖ –¢—Ä–µ–∫–µ—Ä {self.tracker_type} –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å bbox: {bbox}")
            else:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç—Ä–µ–∫–µ—Ä —Å –≤—ã–±—Ä–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç—å—é")
            return success
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç—Ä–µ–∫–µ—Ä–∞: {e}")
            return False

    def update_tracking(self, frame):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏ —Ç—Ä–µ–∫–µ—Ä–∞"""
        if not self.is_initialized or self.tracker is None:
            return False, None

        try:
            start_time = time.time()
            success, bbox = self.tracker.update(frame)
            processing_time = time.time() - start_time

            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            self.analyzer.update(success, bbox, processing_time)

            if success:
                # –û–±–Ω–æ–≤–ª—è–µ–º —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—é
                x, y, w, h = bbox
                center = (int(x + w / 2), int(y + h / 2))
                self.trajectory.append(center)

                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏
                if len(self.trajectory) > 50:
                    self.trajectory.pop(0)

            return success, bbox

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç—Ä–µ–∫–µ—Ä–∞: {e}")
            return False, None


class CustomMeanShiftTracker:
    """–°–æ–±—Å—Ç–≤–µ–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è MeanShift —Ç—Ä–µ–∫–µ—Ä–∞"""

    def __init__(self):
        self.roi_hist = None
        self.track_window = None
        self.termination_criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)

    def init(self, frame, bbox):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–∫–µ—Ä–∞"""
        x, y, w, h = [int(v) for v in bbox]
        self.track_window = (x, y, w, h)

        # –í—ã–¥–µ–ª—è–µ–º ROI
        roi = frame[y:y + h, x:x + w]
        hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)

        # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –∏ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É
        mask = cv2.inRange(hsv_roi, np.array((0., 60., 32.)), np.array((180., 255., 255.)))
        self.roi_hist = cv2.calcHist([hsv_roi], [0], mask, [180], [0, 180])
        cv2.normalize(self.roi_hist, self.roi_hist, 0, 255, cv2.NORM_MINMAX)

        return True

    def update(self, frame):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–∞"""
        if self.roi_hist is None:
            return False, None

        try:
            start_time = time.time()

            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            dst = cv2.calcBackProject([hsv], [0], self.roi_hist, [0, 180], 1)

            # –ü—Ä–∏–º–µ–Ω—è–µ–º MeanShift
            ret, self.track_window = cv2.meanShift(dst, self.track_window, self.termination_criteria)

            processing_time = time.time() - start_time

            if ret:
                x, y, w, h = self.track_window
                return True, (x, y, w, h), processing_time
            else:
                return False, None, processing_time

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ CustomMeanShiftTracker: {e}")
            return False, None, 0


def create_test_videos():
    """–°–æ–∑–¥–∞–µ—Ç –Ω–∞–±–æ—Ä —Ç–µ—Å—Ç–æ–≤—ã—Ö –≤–∏–¥–µ–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    videos_info = []

    # 1. –ü—Ä–æ—Å—Ç–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ (–±–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç)
    video1 = "test_simple_motion.mp4"
    if not os.path.exists(video1):
        print("üé• –°–æ–∑–¥–∞–µ–º –≤–∏–¥–µ–æ —Å –ø—Ä–æ—Å—Ç—ã–º –¥–≤–∏–∂–µ–Ω–∏–µ–º...")
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(video1, fourcc, 25.0, (800, 600))

        for i in range(100):
            frame = np.full((600, 800, 3), 50, dtype=np.uint8)

            # –ü—Ä–æ—Å—Ç–∞—è —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è
            center_x = 100 + int(600 * (i / 100))
            center_y = 300

            # –†–∏—Å—É–µ–º –æ–±—ä–µ–∫—Ç
            cv2.rectangle(frame, (center_x - 40, center_y - 30), (center_x + 40, center_y + 30), (0, 0, 200), -1)
            cv2.rectangle(frame, (center_x - 40, center_y - 30), (center_x + 40, center_y + 30), (0, 0, 255), 2)

            out.write(frame)
        out.release()
        videos_info.append((video1, "–ü—Ä–æ—Å—Ç–æ–µ –ª–∏–Ω–µ–π–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ", 25, 100))

    # 2. –î–≤–∏–∂–µ–Ω–∏–µ —Å –∏–∑–º–µ–Ω–µ–Ω–∏–µ–º –º–∞—Å—à—Ç–∞–±–∞
    video2 = "test_scale_change.mp4"
    if not os.path.exists(video2):
        print("üé• –°–æ–∑–¥–∞–µ–º –≤–∏–¥–µ–æ —Å –∏–∑–º–µ–Ω–µ–Ω–∏–µ–º –º–∞—Å—à—Ç–∞–±–∞...")
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(video2, fourcc, 25.0, (800, 600))

        for i in range(100):
            frame = np.full((600, 800, 3), 50, dtype=np.uint8)

            center_x = 400
            center_y = 300
            size = 20 + int(60 * abs(np.sin(i * 0.1)))

            cv2.rectangle(frame, (center_x - size, center_y - size), (center_x + size, center_y + size), (0, 200, 0),
                          -1)
            cv2.rectangle(frame, (center_x - size, center_y - size), (center_x + size, center_y + size), (0, 255, 0), 2)

            out.write(frame)
        out.release()
        videos_info.append((video2, "–ò–∑–º–µ–Ω–µ–Ω–∏–µ –º–∞—Å—à—Ç–∞–±–∞", 25, 100))

    # 3. –ë—ã—Å—Ç—Ä–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ
    video3 = "test_fast_motion.mp4"
    if not os.path.exists(video3):
        print("üé• –°–æ–∑–¥–∞–µ–º –≤–∏–¥–µ–æ —Å –±—ã—Å—Ç—Ä—ã–º –¥–≤–∏–∂–µ–Ω–∏–µ–º...")
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(video3, fourcc, 25.0, (800, 600))

        for i in range(100):
            frame = np.full((600, 800, 3), 50, dtype=np.uint8)

            center_x = 100 + (i * 7) % 600
            center_y = 100 + int(100 * np.sin(i * 0.3))

            cv2.rectangle(frame, (center_x - 30, center_y - 30), (center_x + 30, center_y + 30), (200, 0, 0), -1)
            cv2.rectangle(frame, (center_x - 30, center_y - 30), (center_x + 30, center_y + 30), (255, 0, 0), 2)

            out.write(frame)
        out.release()
        videos_info.append((video3, "–ë—ã—Å—Ç—Ä–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ", 25, 100))

    # 4. –î–≤–∏–∂–µ–Ω–∏–µ —Å occlusion (–ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º)
    video4 = "test_occlusion.mp4"
    if not os.path.exists(video4):
        print("üé• –°–æ–∑–¥–∞–µ–º –≤–∏–¥–µ–æ —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º...")
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(video4, fourcc, 25.0, (800, 600))

        for i in range(150):
            frame = np.full((600, 800, 3), 50, dtype=np.uint8)

            # –û—Å–Ω–æ–≤–Ω–æ–π –æ–±—ä–µ–∫—Ç
            center_x = 100 + int(400 * (i / 150))
            center_y = 300

            cv2.rectangle(frame, (center_x - 40, center_y - 30), (center_x + 40, center_y + 30), (0, 0, 200), -1)
            cv2.rectangle(frame, (center_x - 40, center_y - 30), (center_x + 40, center_y + 30), (0, 0, 255), 2)

            # –ü–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–∏–π –æ–±—ä–µ–∫—Ç (–Ω–∞ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –∫–∞–¥—Ä–∞—Ö)
            if 50 <= i <= 100:
                occlusion_x = center_x + 20
                cv2.rectangle(frame, (occlusion_x - 50, center_y - 40), (occlusion_x + 50, center_y + 40),
                              (100, 100, 100), -1)

            out.write(frame)
        out.release()
        videos_info.append((video4, "–î–≤–∏–∂–µ–Ω–∏–µ —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º", 25, 150))

    # 5. –°–ª–æ–∂–Ω–∞—è —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è
    video5 = "test_complex_trajectory.mp4"
    if not os.path.exists(video5):
        print("üé• –°–æ–∑–¥–∞–µ–º –≤–∏–¥–µ–æ —Å–æ —Å–ª–æ–∂–Ω–æ–π —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–µ–π...")
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(video5, fourcc, 25.0, (800, 600))

        for i in range(120):
            frame = np.full((600, 800, 3), 50, dtype=np.uint8)

            t = i / 30
            center_x = 400 + int(200 * np.cos(t) * np.sin(2 * t))
            center_y = 300 + int(150 * np.sin(t) * np.cos(3 * t))

            cv2.rectangle(frame, (center_x - 35, center_y - 25), (center_x + 35, center_y + 25), (200, 200, 0), -1)
            cv2.rectangle(frame, (center_x - 35, center_y - 25), (center_x + 35, center_y + 25), (255, 255, 0), 2)

            out.write(frame)
        out.release()
        videos_info.append((video5, "–°–ª–æ–∂–Ω–∞—è —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è", 25, 120))

    return videos_info


def run_comparative_analysis():
    """–ó–∞–ø—É—Å–∫ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–∫–µ—Ä–æ–≤"""
    print("\n" + "=" * 60)
    print("üî¨ –ó–ê–ü–£–°–ö –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê –¢–†–ï–ö–ï–†–û–í")
    print("=" * 60)

    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –≤–∏–¥–µ–æ
    test_videos = create_test_videos()

    # –¢—Ä–µ–∫–µ—Ä—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    trackers_to_test = ['CSRT', 'KCF', 'MOSSE']

    results = {}

    for video_path, description, fps, total_frames in test_videos:
        print(f"\nüìπ –ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ: {description}")
        print(f"   –§–∞–π–ª: {video_path}")
        print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {fps} FPS, {total_frames} –∫–∞–¥—Ä–æ–≤")

        video_results = {}

        for tracker_type in trackers_to_test:
            print(f"\n   üîÑ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç—Ä–µ–∫–µ—Ä–∞: {tracker_type}")

            # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç—Ä–µ–∫–∏–Ω–≥
            metrics = run_single_tracking_test(video_path, tracker_type, description)
            video_results[tracker_type] = metrics

            print(f"      ‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤: {metrics['success_rate']:.1f}%")
            print(f"      ‚è±Ô∏è  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {metrics['average_processing_time'] * 1000:.1f}ms")
            print(f"      üìâ –ß–∞—Å—Ç–æ—Ç–∞ –ø–æ—Ç–µ—Ä—å: {metrics['tracking_loss_frequency']:.1f}%")

        results[description] = video_results

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    save_comparison_results(results, test_videos)

    # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
    create_summary_table(results)

    return results


def run_single_tracking_test(video_path, tracker_type, video_description):
    """–ó–∞–ø—É—Å–∫ –æ–¥–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ —Ç—Ä–µ–∫–∏–Ω–≥–∞"""
    cap = cv2.VideoCapture(video_path)

    if not cap.isOpened():
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ: {video_path}")
        return None

    # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º—É —Ç—Ä–µ–∫–∏–Ω–≥–∞
    tracking_system = TrackingSystem()

    if not tracking_system.initialize_tracker(tracker_type):
        cap.release()
        return None

    # –ß–∏—Ç–∞–µ–º –ø–µ—Ä–≤—ã–π –∫–∞–¥—Ä –∏ –≤—ã–±–∏—Ä–∞–µ–º –æ–±—ä–µ–∫—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
    ret, frame = cap.read()
    if not ret:
        cap.release()
        return None

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä bbox (—Ü–µ–Ω—Ç—Ä –∫–∞–¥—Ä–∞)
    height, width = frame.shape[:2]
    bbox = (width // 2 - 50, height // 2 - 50, 100, 100)

    if not tracking_system.init_tracking(frame, bbox):
        cap.release()
        return None

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –∫–∞–¥—Ä—ã
    frame_count = 1
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        success, bbox = tracking_system.update_tracking(frame)
        frame_count += 1

    cap.release()

    # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
    metrics = tracking_system.analyzer.calculate_metrics()
    return metrics


def run_custom_tracker_test():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ç—Ä–µ–∫–µ—Ä–∞"""
    print("\nüß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –°–û–ë–°–¢–í–ï–ù–ù–û–ô –†–ï–ê–õ–ò–ó–ê–¶–ò–ò TRACKER")

    test_videos = create_test_videos()
    custom_tracker_results = {}

    for video_path, description, fps, total_frames in test_videos:
        print(f"\nüìπ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –≤–∏–¥–µ–æ: {description}")

        cap = cv2.VideoCapture(video_path)

        if not cap.isOpened():
            continue

        # –°–æ–∑–¥–∞–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–π —Ç—Ä–µ–∫–µ—Ä
        custom_tracker = CustomMeanShiftTracker()
        analyzer = TrackingAnalyzer()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        ret, frame = cap.read()
        if not ret:
            cap.release()
            continue

        height, width = frame.shape[:2]
        bbox = (width // 2 - 50, height // 2 - 50, 100, 100)

        if not custom_tracker.init(frame, bbox):
            cap.release()
            continue

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–æ–≤
        frame_count = 1
        while True:
            ret, frame = cap.read()
            if not ret:
                break

            success, bbox, processing_time = custom_tracker.update(frame)
            if success:
                analyzer.update(True, bbox, processing_time)
            else:
                analyzer.update(False, None, processing_time)

            frame_count += 1

        cap.release()

        metrics = analyzer.calculate_metrics()
        custom_tracker_results[description] = metrics

        print(f"   ‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤: {metrics['success_rate']:.1f}%")
        print(f"   ‚è±Ô∏è  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {metrics['average_processing_time'] * 1000:.1f}ms")

    return custom_tracker_results


def save_comparison_results(results, videos_info):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"tracking_comparison_{timestamp}.json"

    output_data = {
        'test_date': timestamp,
        'test_videos': [
            {
                'description': desc,
                'file_path': path,
                'fps': fps,
                'total_frames': frames
            } for (path, desc, fps, frames) in videos_info
        ],
        'results': results
    }

    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)

    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {filename}")
    return filename


def create_summary_table(results):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    print("\n" + "=" * 80)
    print("üìä –°–í–û–î–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê")
    print("=" * 80)

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∞–±–ª–∏—Ü—ã
    print(
        f"\n{'–í–∏–¥–µ–æ —Ç–µ—Å—Ç':<25} {'–¢—Ä–µ–∫–µ—Ä':<8} {'–£—Å–ø–µ—à–Ω–æ—Å—Ç—å (%)':<15} {'–ü–æ—Ç–µ—Ä–∏ (%)':<12} {'–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ (%)':<18} {'–í—Ä–µ–º—è (ms)':<12} {'–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å':<12}")
    print("-" * 110)

    for video_name, video_results in results.items():
        print(f"{video_name:<25}")
        for tracker_name, metrics in video_results.items():
            print(f"{'':<25} {tracker_name:<8} {metrics['success_rate']:<15.1f} "
                  f"{metrics['tracking_loss_frequency']:<12.1f} {metrics['recovery_rate']:<18.1f} "
                  f"{metrics['average_processing_time'] * 1000:<12.1f} {metrics['stability_score']:<12.1f}")


def run_interactive_demo():
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã —Ç—Ä–µ–∫–µ—Ä–æ–≤"""
    print("\nüéÆ –ó–ê–ü–£–°–ö –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–û–ô –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–ò")

    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –≤–∏–¥–µ–æ
    test_videos = create_test_videos()

    if not test_videos:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –≤–∏–¥–µ–æ")
        return

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤–æ–µ –≤–∏–¥–µ–æ –¥–ª—è –¥–µ–º–æ
    video_path = test_videos[0][0]
    description = test_videos[0][1]

    print(f"üé¨ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –Ω–∞ –≤–∏–¥–µ–æ: {description}")

    cap = cv2.VideoCapture(video_path)

    if not cap.isOpened():
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ: {video_path}")
        return

    # –í—ã–±–æ—Ä —Ç—Ä–µ–∫–µ—Ä–∞
    print("\nüîß –í—ã–±–µ—Ä–∏—Ç–µ —Ç—Ä–µ–∫–µ—Ä –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏:")
    print("   1. CSRT (—Ç–æ—á–Ω—ã–π)")
    print("   2. KCF (–±–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏/—Ç–æ—á–Ω–æ—Å—Ç–∏)")
    print("   3. MOSSE (–±—ã—Å—Ç—Ä—ã–π)")
    print("   4. Custom MeanShift (—Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è)")

    choice = input("–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä (1-4): ").strip()

    tracker_map = {'1': 'CSRT', '2': 'KCF', '3': 'MOSSE', '4': 'CUSTOM'}
    tracker_type = tracker_map.get(choice, 'KCF')

    if tracker_type == 'CUSTOM':
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–π —Ç—Ä–µ–∫–µ—Ä
        tracker = CustomMeanShiftTracker()
        use_custom = True
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∏–±–ª–∏–æ—Ç–µ—á–Ω—ã–π —Ç—Ä–µ–∫–µ—Ä
        tracking_system = TrackingSystem()
        tracking_system.initialize_tracker(tracker_type)
        use_custom = False

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    ret, frame = cap.read()
    if not ret:
        cap.release()
        return

    height, width = frame.shape[:2]
    bbox = (width // 2 - 50, height // 2 - 50, 100, 100)

    if use_custom:
        tracker.init(frame, bbox)
    else:
        tracking_system.init_tracking(frame, bbox)

    print(f"\nüöÄ –ó–∞–ø—É—Å–∫ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Å —Ç—Ä–µ–∫–µ—Ä–æ–º: {tracker_type}")
    print("üéÆ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: q - –≤—ã—Ö–æ–¥, r - –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫, p - –ø–∞—É–∑–∞")

    paused = False

    while True:
        if not paused:
            ret, frame = cap.read()
            if not ret:
                break

            display_frame = frame.copy()

            if use_custom:
                success, bbox, _ = tracker.update(frame)
            else:
                success, bbox = tracking_system.update_tracking(frame)

            if success:
                x, y, w, h = [int(v) for v in bbox]
                cv2.rectangle(display_frame, (x, y), (x + w, y + h), (0, 255, 0), 3)

                if not use_custom:
                    # –†–∏—Å—É–µ–º —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –±–∏–±–ª–∏–æ—Ç–µ—á–Ω—ã—Ö —Ç—Ä–µ–∫–µ—Ä–æ–≤
                    for i in range(1, len(tracking_system.trajectory)):
                        cv2.line(display_frame,
                                 tracking_system.trajectory[i - 1],
                                 tracking_system.trajectory[i],
                                 (255, 255, 0), 2)

            cv2.putText(display_frame, f"Tracker: {tracker_type}", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(display_frame, "Status: TRACKING" if success else "Status: LOST",
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7,
                        (0, 255, 0) if success else (0, 0, 255), 2)

            cv2.imshow(f"Tracking Demo - {tracker_type}", display_frame)

        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('r'):
            # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫
            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
            ret, frame = cap.read()
            if ret:
                if use_custom:
                    tracker.init(frame, bbox)
                else:
                    tracking_system.init_tracking(frame, bbox)
        elif key == ord('p'):
            paused = not paused

    cap.release()
    cv2.destroyAllWindows()


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("–°–ò–°–¢–ï–ú–ê –ê–ù–ê–õ–ò–ó–ê –ú–ï–¢–û–î–û–í –¢–†–ï–ö–ò–ù–ì–ê")
    print("\n–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã:")
    print("1. –ü–æ–ª–Ω—ã–π —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–≤—Å–µ —Ç—Ä–µ–∫–µ—Ä—ã + –≤—Å–µ –≤–∏–¥–µ–æ)")
    print("2. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ç—Ä–µ–∫–µ—Ä–∞")
    print("3. –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è")
    print("4. –¢–æ–ª—å–∫–æ —Å–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –≤–∏–¥–µ–æ")

    choice = input("–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä (1-4): ").strip()

    if choice == '1':
        # –ü–æ–ª–Ω—ã–π —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        results = run_comparative_analysis()

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Ç–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–π —Ç—Ä–µ–∫–µ—Ä
        print("\n" + "=" * 60)
        print("–î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –°–û–ë–°–¢–í–ï–ù–ù–û–ì–û –¢–†–ï–ö–ï–†–ê")
        print("=" * 60)

        custom_results = run_custom_tracker_test()

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–π —Ç—Ä–µ–∫–µ—Ä –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for video_name, metrics in custom_results.items():
            if video_name in results:
                results[video_name]['CUSTOM'] = metrics

        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–∞–±–ª–∏—Ü—É
        create_summary_table(results)

    elif choice == '2':
        # –¢–æ–ª—å–∫–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ —Ç—Ä–µ–∫–µ—Ä–∞
        custom_results = run_custom_tracker_test()

        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print("\n–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ö–ê–°–¢–û–ú–ù–û–ì–û –¢–†–ï–ö–ï–†–ê:")
        for video_name, metrics in custom_results.items():
            print(f"\n{video_name}:")
            print(f"  –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {metrics['success_rate']:.1f}%")
            print(f"  –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {metrics['average_processing_time'] * 1000:.1f}ms")
            print(f"  –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: {metrics['stability_score']:.1f}%")

    elif choice == '3':
        # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è
        run_interactive_demo()

    elif choice == '4':
        # –¢–æ–ª—å–∫–æ —Å–æ–∑–¥–∞–Ω–∏–µ –≤–∏–¥–µ–æ
        videos = create_test_videos()
        print(f"\n–°–æ–∑–¥–∞–Ω–æ {len(videos)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –≤–∏–¥–µ–æ:")
        for path, desc, fps, frames in videos:
            print(f"   {desc}: {path}")
    else:
        print("–ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")


if __name__ == "__main__":
    main()
    print("\n–ü–†–û–ì–†–ê–ú–ú–ê –ó–ê–í–ï–†–®–ï–ù–ê!")